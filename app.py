import streamlit as st
import ollama
import time

# --- 1. C·∫§U H√åNH ---
# Thay DeepSeek b·∫±ng Yi-Coder (th√¥ng minh h∆°n)
MODELS = [
    'yi-coder:1.5b', 
    'qwen2.5-coder:1.5b', 
    'llama3.2:1b'
]

st.set_page_config(page_title="AI Code Reviewer", page_icon="ü§ñ", layout="wide")
st.title("ü§ñ Ph√¢n t√≠ch m√£ l·∫≠p tr√¨nh b·∫±ng LLM")

# --- 2. H√ÄM T·∫†O PROMPT (KH·ªöP Y√äU C·∫¶U ƒê·ªÄ B√ÄI) ---
def make_strict_prompt(code_input):
    # D√πng bi·∫øn backtick ƒë·ªÉ tr√°nh l·ªói hi·ªÉn th·ªã khi copy code
    bt = "`" * 3
    
    # Prompt song ng·ªØ: H∆∞·ªõng d·∫´n b·∫±ng Ti·∫øng Anh (ƒë·ªÉ model hi·ªÉu) 
    # nh∆∞ng y√™u c·∫ßu Output Ti√™u ƒë·ªÅ Ti·∫øng Vi·ªát.
    prompt = f"""
You are a Senior Code Reviewer. Analyze the code below.
You MUST reply using EXACTLY the following structure with these specific headers in Vietnamese:

### 1. T√≥m t·∫Øt code
(Summarize what the code does in 1-2 sentences in Vietnamese)

### 2. Danh s√°ch l·ªói ho·∫∑c nguy c∆° bug
(List logic errors, syntax errors, or security issues using bullet points in Vietnamese)
- L·ªói 1: ...
- L·ªói 2: ...

### 3. G·ª£i √Ω t·ªëi ∆∞u
(Provide the full fixed and optimized code inside a Python code block)
{bt}python
# Code ƒë√£ s·ª≠a
{bt}

---
CODE TO ANALYZE:
{bt}python
{code_input}
{bt}
"""
    return prompt

# --- 3. H√ÄM X·ª¨ L√ù CH√çNH ---
def process_input(content, is_file=False):
    # Hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng (x·ª≠ l√Ω chu·ªói an to√†n)
    display_text = content
    if is_file:
        display_text = f"üìÑ **ƒê√£ g·ª≠i file code:**\n```python\n{content}\n```"
    
    st.session_state.messages.append({"role": "user", "content": display_text})
    with st.chat_message("user"):
        st.markdown(display_text)

    # T·∫†O PROMPT
    strict_prompt = make_strict_prompt(content)
    
    with st.chat_message("assistant"):
        st.write("üîç ƒêang ph√¢n t√≠ch l·∫ßn l∆∞·ª£t t·ª´ng model...")
        
        outputs = [] 
        
        # Ch·∫°y v√≤ng l·∫∑p qua t·ª´ng model
        for i, model_name in enumerate(MODELS):
            st.markdown(f"### ü§ñ Model: **{model_name}**")
            status_box = st.empty()
            status_box.info(f"‚è≥ {model_name} ƒëang ch·∫°y...")
            
            try:
                start_time = time.time()
                # G·ªçi Ollama (keep_alive=0 ƒë·ªÉ x·∫£ RAM ngay)
                response = ollama.chat(model=model_name, keep_alive=0, messages=[
                    {'role': 'system', 'content': "You strictly follow the requested format."},
                    {'role': 'user', 'content': strict_prompt},
                ])
                duration = round(time.time() - start_time, 2)
                result_text = response['message']['content']
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                status_box.empty()
                st.success(f"‚è±Ô∏è Xong trong {duration}s")
                st.markdown(result_text)
                
                outputs.append(result_text)
                
            except Exception as e:
                st.error(f"L·ªói: {e} (B·∫°n ƒë√£ 'ollama pull {model_name}' ch∆∞a?)")
                outputs.append(str(e))
            
            # K·∫ª ƒë∆∞·ªùng g·∫°ch ngang ph√¢n c√°ch
            st.divider()
            
            # Ngh·ªâ 0.5s ƒë·ªÉ x·∫£ RAM
            time.sleep(0.5)

        # L∆∞u k·∫øt qu·∫£ v√†o l·ªãch s·ª≠
        st.session_state.messages.append({
            "role": "assistant", 
            "content": outputs, 
            "type": "vertical" 
        })

# --- 4. GIAO DI·ªÜN CH√çNH ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat c≈©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message.get("type") == "vertical":
            for i, content in enumerate(message["content"]):
                if i < len(MODELS): 
                    st.markdown(f"### ü§ñ Model: **{MODELS[i]}**")
                    st.markdown(content)
                    st.divider()
        elif message.get("type") == "comparison": 
             cols = st.columns(3)
             for i, content in enumerate(message["content"]):
                with cols[i]:
                    st.markdown(f"**{MODELS[i]}**")
                    st.markdown(content)
        else:
            st.markdown(message["content"])

st.write("---") 

# --- 5. KHU V·ª∞C NH·∫¨P LI·ªÜU ---
with st.expander("üìé ƒê√≠nh k√®m File Code (Click ƒë·ªÉ m·ªü)", expanded=False):
    uploaded_file = st.file_uploader("Ch·ªçn file code (.py, .txt...)", label_visibility="collapsed")
    if uploaded_file and st.button("‚¨ÜÔ∏è G·ª≠i File n√†y"):
        file_content = uploaded_file.getvalue().decode("utf-8")
        process_input(file_content, is_file=True)
        st.rerun()

# √î Chat Input
if prompt := st.chat_input("Nh·∫≠p code ho·∫∑c c√¢u h·ªèi v√†o ƒë√¢y..."):
    process_input(prompt, is_file=False)